{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489af675-d8f7-475e-a518-ff8eee0ae6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data for benchmarking\n",
    "\n",
    "# Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glycoforge import simulate\n",
    "from methods import combat, add_noise_to_zero_variance_features, percentile_normalization, ratio_preserving_combat, harmony_correction, limma_style_correction, stratified_combat\n",
    "from evaluation import quantify_batch_effect_impact, compare_differential_expression\n",
    "from glycoforge.utils import clr, invclr\n",
    "import json\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "  'bio_strength': [0.5, 1.0, 1.5, 2.0],\n",
    "  'kappa_mu': [0.5, 1.0, 1.5, 2.0],\n",
    "  'var_b': [0.3, 0.5, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Run grid comparison\n",
    "results_list = []\n",
    "base_config = {\n",
    "  'data_source': 'simulated',\n",
    "  'n_glycans': 50,\n",
    "  'n_H': 15,\n",
    "  'n_U': 15,\n",
    "  'k_dir': 100,\n",
    "  'n_batches': 3,\n",
    "  'random_seeds': [42, 43, 44],\n",
    "  'verbose': False,\n",
    "  'save_csv': True\n",
    "}\n",
    "total_runs = len(param_grid['bio_strength']) * len(param_grid['kappa_mu']) * len(param_grid['var_b'])\n",
    "run_idx = 0\n",
    "for bio_strength in param_grid['bio_strength']:\n",
    "  for kappa_mu in param_grid['kappa_mu']:\n",
    "    for var_b in param_grid['var_b']:\n",
    "      run_idx += 1\n",
    "      print(f\"[{run_idx}/{total_runs}] bio={bio_strength}, kappa={kappa_mu}, var_b={var_b}\")\n",
    "      config = base_config.copy()\n",
    "      config.update({'bio_strength': bio_strength, 'kappa_mu': kappa_mu, 'var_b': var_b, 'output_dir': f'results/grid_{bio_strength}_{kappa_mu}_{var_b}'})\n",
    "      simulate(**config)\n",
    "      for seed in config['random_seeds']:\n",
    "        output_dir = config['output_dir']\n",
    "        Y_clean = pd.read_csv(f\"{output_dir}/1_Y_clean_seed{seed}.csv\", index_col=0)\n",
    "        Y_clean_clr = pd.read_csv(f\"{output_dir}/1_Y_clean_clr_seed{seed}.csv\", index_col=0)\n",
    "        Y_with_batch = pd.read_csv(f\"{output_dir}/2_Y_with_batch_seed{seed}.csv\", index_col=0)\n",
    "        Y_with_batch_clr = pd.read_csv(f\"{output_dir}/2_Y_with_batch_clr_seed{seed}.csv\", index_col=0)\n",
    "        with open(f\"{output_dir}/metadata_seed{seed}.json\") as f:\n",
    "          metadata = json.load(f)\n",
    "        batch_labels = np.array(metadata['sample_info']['batch_labels'])\n",
    "        bio_labels = np.array(metadata['sample_info']['bio_labels'])\n",
    "        bio_groups = metadata['sample_info']['bio_groups']\n",
    "        Y_with_batch_clr_fixed = add_noise_to_zero_variance_features(Y_with_batch_clr, noise_level=1e-10, random_seed=seed)\n",
    "        Y_combat_clr = pd.DataFrame(\n",
    "          combat(Y_with_batch_clr_fixed.values, batch_labels, mod=bio_labels),\n",
    "          index=Y_with_batch_clr.index, columns=Y_with_batch_clr.columns\n",
    "        )\n",
    "        Y_combat = pd.DataFrame(index=Y_combat_clr.index, columns=Y_combat_clr.columns)\n",
    "        for sample in Y_combat_clr.columns:\n",
    "          Y_combat[sample] = invclr(Y_combat_clr[sample].values)\n",
    "        Y_percentile = pd.DataFrame(percentile_normalization(Y_with_batch.values, batch_labels), index=Y_with_batch.index, columns=Y_with_batch.columns)\n",
    "        Y_percentile_clr = pd.DataFrame(clr(Y_percentile.values.T).T, index=Y_percentile.index, columns=Y_percentile.columns)\n",
    "        Y_ratio = pd.DataFrame(ratio_preserving_combat(Y_with_batch.values, batch_labels, mod=bio_labels), index=Y_with_batch.index, columns=Y_with_batch.columns)\n",
    "        Y_ratio_clr = pd.DataFrame(clr(Y_ratio.values.T).T, index=Y_ratio.index, columns=Y_ratio.columns)\n",
    "        Y_harmony = pd.DataFrame(harmony_correction(Y_with_batch.values, batch_labels), index=Y_with_batch.index, columns=Y_with_batch.columns)\n",
    "        Y_harmony_clr = pd.DataFrame(clr(Y_harmony.values.T).T, index=Y_harmony.index, columns=Y_harmony.columns)\n",
    "        Y_limma = pd.DataFrame(limma_style_correction(Y_with_batch.values, batch_labels, mod=bio_labels), index=Y_with_batch.index, columns=Y_with_batch.columns)\n",
    "        Y_limma_clr = pd.DataFrame(clr(Y_limma.values.T).T, index=Y_limma.index, columns=Y_limma.columns)\n",
    "        Y_stratified = pd.DataFrame(stratified_combat(Y_with_batch.values, batch_labels, bio_labels), index=Y_with_batch.index, columns=Y_with_batch.columns)\n",
    "        Y_stratified_clr = pd.DataFrame(clr(Y_stratified.values.T).T, index=Y_stratified.index, columns=Y_stratified.columns)\n",
    "        for method_name, Y_corrected, Y_corrected_clr in [\n",
    "          ('combat', Y_combat, Y_combat_clr),\n",
    "          ('percentile', Y_percentile, Y_percentile_clr),\n",
    "          ('ratio', Y_ratio, Y_ratio_clr),\n",
    "          ('harmony', Y_harmony, Y_harmony_clr),\n",
    "          ('limma', Y_limma, Y_limma_clr),\n",
    "          ('stratified', Y_stratified, Y_stratified_clr)\n",
    "        ]:\n",
    "          metrics = quantify_batch_effect_impact(Y_corrected_clr, batch_labels, bio_groups, verbose=False)\n",
    "          de = compare_differential_expression(dataset1=Y_clean, dataset2=Y_with_batch, dataset3=Y_corrected, verbose=False)\n",
    "          results_list.append({\n",
    "            'bio_strength': bio_strength,\n",
    "            'kappa_mu': kappa_mu,\n",
    "            'var_b': var_b,\n",
    "            'seed': seed,\n",
    "            'method': method_name,\n",
    "            'PVCA_batch_variance': metrics['pvca_batch_variance'],\n",
    "            'PVCA_bio_variance': metrics['pvca_bio_variance'],\n",
    "            'PVCA_residual_variance': metrics['pvca_residual_variance'],\n",
    "            'silhouette': metrics['silhouette'],\n",
    "            'kBET': metrics['kBET'],\n",
    "            'LISI': metrics['LISI'],\n",
    "            'ARI': metrics['ARI'],\n",
    "            'comp_effect': metrics['compositional_effect_size'],\n",
    "            'pca_batch': metrics['pca_batch_effect'],\n",
    "            'tp': de['results']['compare_1v3']['after_correction_errors']['tp_count'],\n",
    "            'fp': de['results']['compare_1v3']['after_correction_errors']['fp_count'],\n",
    "            'fn': de['results']['compare_1v3']['after_correction_errors']['fn_count'],\n",
    "            'sig_clean': de['results']['dataset1']['significant_count'],\n",
    "            'sig_corrected': de['results']['dataset3']['significant_count']\n",
    "          })\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(results_list)\n",
    "results_df['tp_rate'] = results_df['tp'] / results_df['sig_clean']\n",
    "results_df['fp_rate'] = results_df['fp'] / (50 - results_df['sig_clean'])\n",
    "results_df['fn_rate'] = results_df['fn'] / results_df['sig_clean']\n",
    "results_df['f1'] = 2 * results_df['tp'] / (2 * results_df['tp'] + results_df['fp'] + results_df['fn'])\n",
    "\n",
    "# Aggregate across seeds\n",
    "agg_results = results_df.groupby(['bio_strength', 'kappa_mu', 'var_b', 'method']).agg({\n",
    "  'PVCA_batch_variance': 'mean',\n",
    "  'PVCA_bio_variance': 'mean',\n",
    "  'PVCA_residual_variance': 'mean',\n",
    "  'silhouette': 'mean',\n",
    "  'kBET': 'mean',\n",
    "  'LISI': 'mean',\n",
    "  'ARI': 'mean',\n",
    "  'comp_effect': 'mean',\n",
    "  'pca_batch': 'mean',\n",
    "  'tp_rate': 'mean',\n",
    "  'fp_rate': 'mean',\n",
    "  'fn_rate': 'mean',\n",
    "  'f1': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Find winner for each metric and condition\n",
    "def find_winners(df, metric, lower_is_better=True):\n",
    "  winners = []\n",
    "  for (bio, kappa, var_b), group in df.groupby(['bio_strength', 'kappa_mu', 'var_b']):\n",
    "    if lower_is_better:\n",
    "      best = group.loc[group[metric].idxmin(), 'method']\n",
    "    else:\n",
    "      best = group.loc[group[metric].idxmax(), 'method']\n",
    "    winners.append({'bio_strength': bio, 'kappa_mu': kappa, 'var_b': var_b, 'winner': best})\n",
    "  return pd.DataFrame(winners)\n",
    "\n",
    "# Overall winner counts\n",
    "print(\"=== WINNER COUNTS BY METRIC ===\")\n",
    "for metric, lower_better in [('PVCA_batch_variance', True), ('silhouette', True), ('kBET', True), ('ARI', True), ('comp_effect', True), ('pca_batch', True), ('LISI', False), ('f1', False), ('tp_rate', False), ('fp_rate', True), ('fn_rate', True)]:\n",
    "  winners = find_winners(agg_results, metric, lower_better)\n",
    "  counts = winners['winner'].value_counts()\n",
    "  print(f\"\\n{metric} ({'lower' if lower_better else 'higher'} is better):\")\n",
    "  print(counts)\n",
    "\n",
    "# Visualize by condition severity\n",
    "agg_results['batch_severity'] = agg_results['kappa_mu'] + agg_results['var_b']\n",
    "agg_results['bio_effect_strength'] = agg_results['bio_strength']\n",
    "severity_summary = agg_results.groupby(['method', pd.cut(agg_results['batch_severity'], bins=[0, 1.0, 1.5, 2.0, 3.0], labels=['weak', 'moderate', 'strong', 'extreme'])]).agg({\n",
    "  'PVCA_batch_variance': 'mean',\n",
    "  'PVCA_bio_variance': 'mean',\n",
    "  'f1': 'mean',\n",
    "  'kBET': 'mean',\n",
    "  'silhouette': 'mean'\n",
    "}).round(4)\n",
    "print(\"\\n=== PERFORMANCE BY BATCH SEVERITY ===\")\n",
    "print(severity_summary)\n",
    "\n",
    "# Best method recommendation by scenario\n",
    "print(\"\\n=== RECOMMENDATION BY SCENARIO ===\")\n",
    "for bio in param_grid['bio_strength']:\n",
    "  for severity in ['weak', 'moderate', 'strong', 'extreme']:\n",
    "    if severity == 'weak':\n",
    "      conditions = agg_results[(agg_results['bio_strength'] == bio) & (agg_results['batch_severity'] <= 1.0)]\n",
    "    elif severity == 'moderate':\n",
    "      conditions = agg_results[(agg_results['bio_strength'] == bio) & (agg_results['batch_severity'] > 1.0) & (agg_results['batch_severity'] <= 1.5)]\n",
    "    elif severity == 'strong':\n",
    "      conditions = agg_results[(agg_results['bio_strength'] == bio) & (agg_results['batch_severity'] > 1.5) & (agg_results['batch_severity'] <= 2.0)]\n",
    "    else:\n",
    "      conditions = agg_results[(agg_results['bio_strength'] == bio) & (agg_results['batch_severity'] > 2.0)]\n",
    "    if len(conditions) > 0:\n",
    "      best_f1 = conditions.loc[conditions['f1'].idxmax(), 'method']\n",
    "      best_batch = conditions.loc[conditions['kBET'].idxmin(), 'method']\n",
    "      print(f\"Bio={bio}, Batch={severity:8s}: Best F1={best_f1:10s}, Best batch removal={best_batch:10s}\")\n",
    "\n",
    "# Save detailed results\n",
    "results_df.to_csv('results/method_comparison_detailed.csv', index=False)\n",
    "agg_results.to_csv('results/method_comparison_aggregated.csv', index=False)\n",
    "print(\"\\nDetailed results saved to results/method_comparison_detailed.csv\")\n",
    "print(\"Aggregated results saved to results/method_comparison_aggregated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a33b0c-4d58-4ee0-ac7f-8da99e3af218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark batch effect removal methods\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load aggregated results\n",
    "agg_results = pd.read_csv('results/method_comparison_aggregated.csv')\n",
    "\n",
    "# 2x2 grid\n",
    "fig = plt.figure(figsize=(18, 14))\n",
    "gs = fig.add_gridspec(2, 2, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# Batch effect reduction across methods (aggregate across all conditions)\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "batch_metrics = ['PVCA_batch_variance', 'silhouette', 'kBET', 'ARI', 'comp_effect', 'pca_batch', 'LISI']\n",
    "method_order = ['combat', 'percentile', 'ratio', 'harmony', 'limma', 'stratified']\n",
    "method_labels = ['ComBat', 'Percentile', 'Ratio-ComBat', 'Harmony', 'Limma', 'Stratified']\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']\n",
    "method_means = agg_results.groupby('method')[batch_metrics].mean()\n",
    "method_means = method_means.reindex(method_order)\n",
    "x = np.arange(len(batch_metrics))\n",
    "width = 0.13\n",
    "for i, method in enumerate(method_order):\n",
    "  offset = (i - 2.5) * width\n",
    "  values = method_means.loc[method].values\n",
    "  ax1.bar(x + offset, values, width, label=method_labels[i], color=colors[i], alpha=0.8, edgecolor='black')\n",
    "ax1.set_xlabel('Batch Effect Metric', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Mean Value', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Panel A: Batch Effect Metrics by Method\\n(averaged across all conditions)', fontsize=13, fontweight='bold')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(['PVCA-Batch↓', 'Silhouette↓', 'kBET↓', 'ARI↓', 'Comp.Eff↓', 'PCA↓', 'LISI↑'], fontsize=9)\n",
    "ax1.legend(fontsize=9, ncol=2)\n",
    "ax1.grid(alpha=0.3, axis='y')\n",
    "\n",
    "# F1 score comparison across batch severity levels\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "agg_results['batch_severity'] = pd.cut(agg_results['kappa_mu'] + agg_results['var_b'], bins=[0, 1.0, 1.5, 2.0, 3.0], labels=['Weak', 'Moderate', 'Strong', 'Extreme'])\n",
    "severity_f1 = agg_results.groupby(['method', 'batch_severity'])['f1'].mean().unstack()\n",
    "severity_f1 = severity_f1.reindex(method_order)\n",
    "severity_f1.plot(kind='bar', ax=ax2, color=['#90EE90', '#FFD700', '#FF8C00', '#DC143C'], edgecolor='black', width=0.8)\n",
    "ax2.set_xlabel('Method', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Mean F1 Score', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Panel B: F1 Score by Batch Severity\\n(DE recovery quality)', fontsize=13, fontweight='bold')\n",
    "ax2.set_xticklabels(method_labels, rotation=45, ha='right', fontsize=10)\n",
    "ax2.legend(title='Batch Severity', fontsize=9)\n",
    "ax2.grid(alpha=0.3, axis='y')\n",
    "ax2.set_ylim(0, 1)\n",
    "\n",
    "# TP vs FP rates scatter\n",
    "ax3 = fig.add_subplot(gs[1, 0])\n",
    "method_summary = agg_results.groupby('method')[['tp_rate', 'fp_rate']].mean()\n",
    "method_summary = method_summary.reindex(method_order)\n",
    "for i, method in enumerate(method_order):\n",
    "  ax3.scatter(method_summary.loc[method, 'fp_rate'], method_summary.loc[method, 'tp_rate'], \n",
    "             s=200, c=colors[i], label=method_labels[i], alpha=0.8, edgecolors='black', linewidths=2)\n",
    "ax3.set_xlabel('Mean False Positive Rate', fontsize=12, fontweight='bold')\n",
    "ax3.set_ylabel('Mean True Positive Rate', fontsize=12, fontweight='bold')\n",
    "ax3.set_title('Panel C: TP vs FP Trade-off\\n(averaged across all conditions)', fontsize=13, fontweight='bold')\n",
    "ax3.plot([0, 1], [0, 1], 'k--', alpha=0.3, label='Random')\n",
    "ax3.legend(fontsize=9)\n",
    "ax3.grid(alpha=0.3)\n",
    "ax3.set_xlim(-0.05, max(method_summary['fp_rate']) * 1.1)\n",
    "ax3.set_ylim(0, 1.05)\n",
    "\n",
    "# Heatmap of best method by condition using composite score\n",
    "ax4 = fig.add_subplot(gs[1, 1])\n",
    "agg_results['batch_severity_score'] = agg_results['kappa_mu'] + agg_results['var_b']\n",
    "# Composite score: minimize batch, maximize bio preservation, maximize DE recovery\n",
    "# Normalize each component to [0,1] scale within each condition\n",
    "pivot_data = []\n",
    "bio_values = sorted(agg_results['bio_strength'].unique())\n",
    "severity_bins = [(0, 1.0), (1.0, 1.5), (1.5, 2.0), (2.0, 3.0)]\n",
    "severity_labels = ['Weak', 'Moderate', 'Strong', 'Extreme']\n",
    "for bio in bio_values:\n",
    "  row = []\n",
    "  for (low, high), label in zip(severity_bins, severity_labels):\n",
    "    subset = agg_results[(agg_results['bio_strength'] == bio) & (agg_results['batch_severity_score'] > low) & (agg_results['batch_severity_score'] <= high)]\n",
    "    if len(subset) > 0:\n",
    "      subset = subset.copy()\n",
    "      subset['pvca_batch_norm'] = (subset['PVCA_batch_variance'].max() - subset['PVCA_batch_variance']) / (subset['PVCA_batch_variance'].max() - subset['PVCA_batch_variance'].min() + 1e-6)\n",
    "      subset['pvca_bio_norm'] = (subset['PVCA_bio_variance'] - subset['PVCA_bio_variance'].min()) / (subset['PVCA_bio_variance'].max() - subset['PVCA_bio_variance'].min() + 1e-6)\n",
    "      subset['f1_norm'] = (subset['f1'] - subset['f1'].min()) / (subset['f1'].max() - subset['f1'].min() + 1e-6)\n",
    "      subset['composite_score'] = 0.5 * subset['pvca_batch_norm'] + 0.3 * subset['pvca_bio_norm'] + 0.2 * subset['f1_norm']\n",
    "      best_method = subset.loc[subset['composite_score'].idxmax(), 'method']\n",
    "      row.append(method_order.index(best_method))\n",
    "    else:\n",
    "      row.append(-1)\n",
    "  pivot_data.append(row)\n",
    "pivot_df = pd.DataFrame(pivot_data, index=[f'Bio={b}' for b in bio_values], columns=severity_labels)\n",
    "im = ax4.imshow(pivot_df.values, cmap='tab10', aspect='auto', vmin=0, vmax=len(method_order)-1)\n",
    "ax4.set_xticks(range(len(severity_labels)))\n",
    "ax4.set_yticks(range(len(bio_values)))\n",
    "ax4.set_xticklabels(severity_labels, fontsize=10)\n",
    "ax4.set_yticklabels([f'Bio={b}' for b in bio_values], fontsize=10)\n",
    "ax4.set_xlabel('Batch Severity', fontsize=12, fontweight='bold')\n",
    "ax4.set_ylabel('Biological Signal Strength', fontsize=12, fontweight='bold')\n",
    "ax4.set_title('Panel D: Best Method by Condition\\n(composite: 50% batch removal, 30% bio preservation, 20% DE recovery)', fontsize=13, fontweight='bold')\n",
    "for i in range(len(bio_values)):\n",
    "  for j in range(len(severity_labels)):\n",
    "    method_idx = pivot_df.iloc[i, j]\n",
    "    if method_idx >= 0:\n",
    "      ax4.text(j, i, method_labels[method_idx], ha='center', va='center', color='white', fontsize=9, fontweight='bold')\n",
    "cbar = plt.colorbar(im, ax=ax4, ticks=range(len(method_order)))\n",
    "cbar.set_ticklabels(method_labels)\n",
    "\n",
    "plt.savefig('results/figures/fig3_method_comparison.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# PVCA variance decomposition\n",
    "fig_pvca, (ax_pvca1, ax_pvca2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "# Left: Stacked bar showing PVCA decomposition by method\n",
    "pvca_decomp = agg_results.groupby('method')[['PVCA_batch_variance', 'PVCA_bio_variance', 'PVCA_residual_variance']].mean()\n",
    "pvca_decomp = pvca_decomp.reindex(method_order)\n",
    "pvca_decomp.plot(kind='bar', stacked=True, ax=ax_pvca1, color=['#DC143C', '#4169E1', '#D3D3D3'], edgecolor='black', width=0.7)\n",
    "ax_pvca1.set_xlabel('Method', fontsize=12, fontweight='bold')\n",
    "ax_pvca1.set_ylabel('Variance Explained (%)', fontsize=12, fontweight='bold')\n",
    "ax_pvca1.set_title('PVCA Variance Decomposition by Method\\n(averaged across all conditions)', fontsize=13, fontweight='bold')\n",
    "ax_pvca1.set_xticklabels(method_labels, rotation=45, ha='right', fontsize=10)\n",
    "ax_pvca1.legend(['Batch', 'Biological', 'Residual'], fontsize=10, loc='upper right')\n",
    "ax_pvca1.set_ylim(0, 100)\n",
    "ax_pvca1.grid(alpha=0.3, axis='y')\n",
    "# Right: Bio vs Batch variance scatter\n",
    "method_pvca = agg_results.groupby('method')[['PVCA_batch_variance', 'PVCA_bio_variance']].mean()\n",
    "method_pvca = method_pvca.reindex(method_order)\n",
    "for i, method in enumerate(method_order):\n",
    "  ax_pvca2.scatter(method_pvca.loc[method, 'PVCA_batch_variance'], method_pvca.loc[method, 'PVCA_bio_variance'], \n",
    "                  s=200, c=colors[i], label=method_labels[i], alpha=0.8, edgecolors='black', linewidths=2)\n",
    "ax_pvca2.plot([0, max(method_pvca['PVCA_batch_variance'])*1.1], [0, max(method_pvca['PVCA_batch_variance'])*1.1], 'k--', alpha=0.3, label='Equal variance')\n",
    "ax_pvca2.set_xlabel('Batch Variance (%)', fontsize=12, fontweight='bold')\n",
    "ax_pvca2.set_ylabel('Biological Variance (%)', fontsize=12, fontweight='bold')\n",
    "ax_pvca2.set_title('PVCA: Biological vs Batch Variance\\n(upper-left = ideal: low batch, high bio)', fontsize=13, fontweight='bold')\n",
    "ax_pvca2.legend(fontsize=9)\n",
    "ax_pvca2.grid(alpha=0.3)\n",
    "ax_pvca2.axvline(x=10, color='orange', linestyle=':', alpha=0.5, label='Batch<10% threshold')\n",
    "ax_pvca2.axhline(y=20, color='green', linestyle=':', alpha=0.5, label='Bio>20% threshold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/figures/fig3_pvca_decomposition.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\n=== FIGURE 3 SUMMARY ===\")\n",
    "print(\"\\nPVCA Variance Decomposition (mean % across all conditions)\")\n",
    "pvca_stats = agg_results.groupby('method')[['PVCA_batch_variance', 'PVCA_bio_variance', 'PVCA_residual_variance']].mean()\n",
    "pvca_stats = pvca_stats.reindex(method_order)\n",
    "pvca_stats.index = method_labels\n",
    "print(pvca_stats.round(2))\n",
    "print(\"\\nPVCA Signal-to-Batch Ratio (Bio/Batch, higher = better)\")\n",
    "pvca_stats['bio_to_batch_ratio'] = pvca_stats['PVCA_bio_variance'] / (pvca_stats['PVCA_batch_variance'] + 1e-6)\n",
    "print(pvca_stats['bio_to_batch_ratio'].round(3))\n",
    "print(\"\\nMean batch effect metrics\")\n",
    "print(method_means.round(3))\n",
    "print(\"\\nF1 by severity\")\n",
    "print(severity_f1.round(3))\n",
    "print(\"\\nTP vs FP rates\")\n",
    "print(method_summary.round(3))\n",
    "print(\"\\nWinner distribution (PVCA-based)\")\n",
    "print(pd.Series(pivot_df.values.flatten()).value_counts())\n",
    "\n",
    "# Sensitivity analysis: Winner consistency across different criteria\n",
    "print(\"\\n=== SENSITIVITY ANALYSIS: WINNER CONSISTENCY ===\")\n",
    "scoring_schemes = {\n",
    "  'PVCA-only': {'PVCA_batch_variance': -1.0},\n",
    "  'PVCA+Bio': {'PVCA_batch_variance': -0.6, 'PVCA_bio_variance': 0.4},\n",
    "  'Composite (main)': {'PVCA_batch_variance': -0.5, 'PVCA_bio_variance': 0.3, 'f1': 0.2},\n",
    "  'F1-only': {'f1': 1.0}\n",
    "}\n",
    "sensitivity_results = {}\n",
    "for scheme_name, weights in scoring_schemes.items():\n",
    "  pivot_data = []\n",
    "  for bio in bio_values:\n",
    "    row = []\n",
    "    for (low, high), label in zip(severity_bins, severity_labels):\n",
    "      subset = agg_results[(agg_results['bio_strength'] == bio) & (agg_results['batch_severity_score'] > low) & (agg_results['batch_severity_score'] <= high)]\n",
    "      if len(subset) > 0:\n",
    "        subset = subset.copy()\n",
    "        subset['score'] = 0\n",
    "        for metric, weight in weights.items():\n",
    "          if weight < 0:\n",
    "            subset['score'] += weight * subset[metric]\n",
    "          else:\n",
    "            subset['score'] += weight * subset[metric]\n",
    "        best_method = subset.loc[subset['score'].idxmax(), 'method']\n",
    "        row.append(best_method)\n",
    "      else:\n",
    "        row.append('none')\n",
    "    pivot_data.append(row)\n",
    "  sensitivity_results[scheme_name] = pd.DataFrame(pivot_data, index=[f'Bio={b}' for b in bio_values], columns=severity_labels)\n",
    "# Check consistency\n",
    "print(\"\\nWinner counts by scoring scheme:\")\n",
    "for scheme_name, df in sensitivity_results.items():\n",
    "  counts = pd.Series(df.values.flatten()).value_counts()\n",
    "  print(f\"\\n{scheme_name}:\")\n",
    "  print(counts)\n",
    "# Calculate agreement between schemes\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "print(\"\\nAgreement between scoring schemes (Cohen's kappa):\")\n",
    "schemes = list(scoring_schemes.keys())\n",
    "for i, scheme1 in enumerate(schemes):\n",
    "  for scheme2 in schemes[i+1:]:\n",
    "    flat1 = sensitivity_results[scheme1].values.flatten()\n",
    "    flat2 = sensitivity_results[scheme2].values.flatten()\n",
    "    mask = (flat1 != 'none') & (flat2 != 'none')\n",
    "    if mask.sum() > 0:\n",
    "      kappa = cohen_kappa_score(flat1[mask], flat2[mask])\n",
    "      print(f\"  {scheme1} vs {scheme2}: κ = {kappa:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
